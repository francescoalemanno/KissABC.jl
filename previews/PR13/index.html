<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Basic Usage ¬∑ KissABC.jl</title><link rel="canonical" href="https://juliaapproxinference.github.io/KissABC.jl/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KissABC.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Basic Usage</a><ul class="internal"><li><a class="tocitem" href="#Usage-guide-1"><span>Usage guide</span></a></li></ul></li><li><a class="tocitem" href="example_1/">Example: Gaussian Mixture</a></li><li><a class="tocitem" href="reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Basic Usage</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Basic Usage</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaApproxInference/KissABC.jl/blob/master/docs/literate/index.jl" title="Edit on GitHub"><span class="docs-icon fab">ÔÇõ</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="KissABC-1"><a class="docs-heading-anchor" href="#KissABC-1">KissABC</a><a class="docs-heading-anchor-permalink" href="#KissABC-1" title="Permalink"></a></h1><h2 id="Usage-guide-1"><a class="docs-heading-anchor" href="#Usage-guide-1">Usage guide</a><a class="docs-heading-anchor-permalink" href="#Usage-guide-1" title="Permalink"></a></h2><p>The ingredients you need to use Approximate Bayesian Computation:</p><ol><li>A simulation which depends on some parameters, able to generate datasets similar to your target dataset if parameters are tuned</li><li>A prior distribution over such parameters</li><li>A distance function to compare generated dataset to the true dataset</li></ol><p>We will start with a simple example, we have a dataset generated according to an Normal distribution whose parameters are unknown</p><pre><code class="language-julia">tdata = randn(1000) .* 0.04 .+ 2;</code></pre><p>we are ofcourse able to simulate normal random numbers, so this constitutes our simulation</p><pre><code class="language-julia">sim((Œº, œÉ)) = randn(1000) .* œÉ .+ Œº;</code></pre><p>The second ingredient is a prior over the parameters Œº and œÉ</p><pre><code class="language-julia">using Distributions
using KissABC
prior = Factored(Uniform(1, 3), Truncated(Normal(0, 0.1), 0, 100));</code></pre><p>we have chosen a uniform distribution over the interval [1,3] for Œº and a normal distribution truncated over ‚Ñù‚Å∫ for œÉ.</p><p>Now all that we need is a distance function to compare the true dataset to the simulated dataset, for this purpose a Kolmogorov-Smirnoff distance is good</p><pre><code class="language-julia">using StatsBase
function ksdist(x, y)
    d1 = mean(x) - mean(y)
    d2 = std(x) - std(y)
    hypot(d1, d2 * 50)
end</code></pre><pre><code class="language-none">ksdist (generic function with 1 method)</code></pre><p>Now we are all set, we can use <code>ABCDE</code> which is sequential Monte Carlo algorithm with an adaptive proposal, to simulate the posterior distribution for this model, inferring Œº and œÉ</p><pre><code class="language-julia">cost(x) = ksdist(tdata, sim(x))
approx_density = ApproxPosterior(prior, cost, 0.1)
res, _ = mcmc(approx_density, nparticles = 2000, generations = 100);</code></pre><pre><code class="language-none">Progress:  12%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                    |  ETA: 0:00:02[K
  generation:       12
  acceptance_rate:  0.197
  avg_particle:     (1.9957609912918868, 0.04865127386594689)
  std_particle:     (0.41826131074937084, 0.026269943317837857)[A[A[A[A



[K[A[K[A[K[A[K[AProgress:  27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                             |  ETA: 0:00:02[K
  generation:       27
  acceptance_rate:  0.2065
  avg_particle:     (2.0009396273484708, 0.0409854991074403)
  std_particle:     (0.21675085114403198, 0.009105261027795583)[A[A[A[A



[K[A[K[A[K[A[K[AProgress:  39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         |  ETA: 0:00:01[K
  generation:       39
  acceptance_rate:  0.264
  avg_particle:     (2.0034296618329894, 0.039612461028971535)
  std_particle:     (0.12205920174990119, 0.0040905011969224825)[A[A[A[A



[K[A[K[A[K[A[K[AProgress:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    |  ETA: 0:00:01[K
  generation:       50
  acceptance_rate:  0.3155
  avg_particle:     (2.0015004120401096, 0.039154100479278885)
  std_particle:     (0.07605022666392917, 0.0024160829218307133)[A[A[A[A



[K[A[K[A[K[A[K[AProgress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                |  ETA: 0:00:01[K
  generation:       60
  acceptance_rate:  0.345
  avg_particle:     (2.002575536612685, 0.038938251751286714)
  std_particle:     (0.06260980168676818, 0.001752244928876055)[A[A[A[A



[K[A[K[A[K[A[K[AProgress:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           |  ETA: 0:00:01[K
  generation:       71
  acceptance_rate:  0.3555
  avg_particle:     (2.0016143276022507, 0.038863248118469376)
  std_particle:     (0.05475401911848216, 0.001469979408287341)[A[A[A[A



[K[A[K[A[K[A[K[AProgress:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       |  ETA: 0:00:00[K
  generation:       82
  acceptance_rate:  0.341
  avg_particle:     (2.0001033704602076, 0.03880454471936824)
  std_particle:     (0.05147613589926686, 0.001393063478137073)[A[A[A[A



[K[A[K[A[K[A[K[AProgress:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  |  ETA: 0:00:00[K
  generation:       93
  acceptance_rate:  0.36
  avg_particle:     (1.9996255772912974, 0.0387577895359444)
  std_particle:     (0.049130134381287174, 0.0013303620391617497)[A[A[A[A



[K[A[K[A[K[A[K[AProgress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:02[K
  generation:       100
  acceptance_rate:  0.344
  avg_particle:     (1.9993438611278822, 0.03877595403785946)
  std_particle:     (0.049972860538267556, 0.0013396869040778418)</code></pre><p>the parameters we chose are: a tolerance on distances equal to <code>0.1</code>, a number of simulated particles equal to <code>200</code>, we enabled Threaded parallelism, and ofcourse the first four parameters are the ingredients we set in the previous steps, the simulated posterior results are in <code>res</code>, while the <code>_</code> is there to simply ignore all the other returned information. We can now extract the inference results:</p><pre><code class="language-julia">prsample = [rand(prior) for i = 1:2000] #some samples from the prior for comparison
Œº_pr = getindex.(prsample, 1) # Œº samples from the prior
œÉ_pr = getindex.(prsample, 2) # œÉ samples from the prior
Œº_p = getindex.(res, 1) # Œº samples from the posterior
œÉ_p = getindex.(res, 2); # œÉ samples from the posterior</code></pre><p>and plotting prior and posterior side by side we get:</p><pre><code class="language-julia">using Plots
a = stephist(
    Œº_pr,
    xlims = (1, 3),
    xlabel = &quot;Œº prior&quot;,
    leg = false,
    lw = 2,
    normalize = true,
)
b = stephist(
    œÉ_pr,
    xlims = (0, 0.3),
    xlabel = &quot;œÉ prior&quot;,
    leg = false,
    lw = 2,
    normalize = true,
)
ap = stephist(
    Œº_p,
    xlims = (1, 3),
    xlabel = &quot;Œº posterior&quot;,
    leg = false,
    lw = 2,
    normalize = true,
)
bp = stephist(
    œÉ_p,
    xlims = (0, 0.3),
    xlabel = &quot;œÉ posterior&quot;,
    leg = false,
    lw = 2,
    normalize = true,
)
plot(a, ap, b, bp)
savefig(&quot;inference.svg&quot;);</code></pre><p><img src="inference.svg" alt="inference_plot"/></p><p>we can see that the algorithm has correctly inferred both parameters, this exact recipe will work for much more complicated models and simulations, with some tuning.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="example_1/">Example: Gaussian Mixture ¬ª</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 28 June 2020 13:36">Sunday 28 June 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
